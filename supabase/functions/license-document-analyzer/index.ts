import "https://deno.land/x/xhr@0.1.0/mod.ts";
import { serve } from "https://deno.land/std@0.168.0/http/server.ts";
import { createClient } from 'https://esm.sh/@supabase/supabase-js@2'

const corsHeaders = {
  'Access-Control-Allow-Origin': '*',
  'Access-Control-Allow-Headers': 'authorization, x-client-info, apikey, content-type',
}

interface DocumentAnalysisRequest {
  documentPath: string;
}

interface ExtractedLicenseFormData {
  nome: string;
  tipo: string;
  orgaoEmissor: string;
  numeroProcesso: string;
  dataEmissao: string;
  dataVencimento: string;
  status: string;
  condicionantes: string;
  structured_conditions: LicenseCondition[];
  alerts: LicenseAlert[];
  compliance_score: number;
  renewal_recommendation: RenewalRecommendation;
  confidence_scores: {
    nome: number;
    tipo: number;
    orgaoEmissor: number;
    numeroProcesso: number;
    dataEmissao: number;
    dataVencimento: number;
    status: number;
    condicionantes: number;
  };
}

interface LicenseCondition {
  condition_text: string;
  condition_category: string;
  priority: 'low' | 'medium' | 'high';
  frequency?: 'Mensal' | 'Trimestral' | 'Semestral' | 'Anual' | 'Unica';
  due_date?: string;
  responsible_area?: string;
  compliance_status: 'pending' | 'in_progress' | 'completed' | 'overdue';
}

interface LicenseAlert {
  type: 'renewal' | 'condition_due' | 'compliance_issue' | 'document_required';
  title: string;
  message: string;
  severity: 'low' | 'medium' | 'high' | 'critical';
  due_date?: string;
  action_required: boolean;
}

interface RenewalRecommendation {
  start_date: string;
  urgency: 'low' | 'medium' | 'high';
  required_documents: string[];
  estimated_cost?: number;
  recommended_actions: string[];
}

interface LicenseContext {
  licenseType?: string;
  issuingBody?: string;
  businessSector?: string;
  activityType?: string;
}

// Specialized prompts based on license context with advanced AI strategies
function getSpecializedPrompt(documentContent: string): string {
  const context = detectLicenseContext(documentContent);
  
  let basePrompt = `
Voc√™ √© um especialista S√äNIOR em licenciamento ambiental brasileiro com 20+ anos de experi√™ncia pr√°tica. Use estrat√©gias avan√ßadas de extra√ß√£o de dados para documentos oficiais brasileiros.

üîç ESTRAT√âGIA DE AN√ÅLISE EM 3 N√çVEIS:

N√çVEL 1 - RECONHECIMENTO CONTEXTUAL:
- Identifique primeiro o TIPO de documento (cabe√ßalho, logotipo, formato)
- Detecte o √ìRG√ÉO emissor atrav√©s de logos, timbres e assinaturas
- Determine o SETOR atrav√©s de atividades descritas

N√çVEL 2 - EXTRA√á√ÉO INTELIGENTE POR PADR√ïES:
- N√öMEROS DE PROCESSO: Procure padr√µes como "Processo n¬∫", "Protocolo:", seguidos de n√∫meros com pontos/barras
- DATAS: Busque "emitida em", "v√°lida at√©", "vencimento em" em formato DD/MM/AAAA ou DD de MMMM de AAAA
- CONDICIONANTES: Identifique por numera√ß√£o (1., 2., I, II) ou bullets, termos como "fica condicionado", "dever√°"
- STATUS: Inferir de datas (se vencida = "Vencida", se ativa = "Ativa")

N√çVEL 3 - VALIDA√á√ÉO CRUZADA:
- Verifique consist√™ncia entre dados extra√≠dos
- Calcule confidence scores baseado na CLAREZA e LOCALIZA√á√ÉO da informa√ß√£o
- Use conhecimento de padr√µes brasileiros para validar

üìç LOCAIS T√çPICOS DE INFORMA√á√ÉO:
- CABE√áALHO: Nome da licen√ßa, √≥rg√£o emissor, logotipo
- PRIMEIRO PAR√ÅGRAFO: N√∫mero de processo, requerente, atividade
- MEIO DO DOCUMENTO: Condicionantes detalhadas (se√ß√£o espec√≠fica)
- FINAL: Datas de emiss√£o e validade, assinaturas

üéØ PADR√ïES ESPEC√çFICOS BRASILEIROS:
- Processos: XXXXXX.XXXXXX/XXXX-XX (IBAMA), outros formatos por √≥rg√£o
- √ìrg√£os: IBAMA, CETESB, INEA, FATMA, FEAM, IAP, SEMAC, etc.
- Tipos: LP, LI, LO, LAS, LAU, LAC, RLO, ARL, etc.
- Datas: DD/MM/AAAA predominante em documentos oficiais

CONTEXTO ATUAL DETECTADO:
- Tipo: ${context.licenseType || 'ANALISAR NO DOCUMENTO'}
- √ìrg√£o: ${context.issuingBody || 'EXTRAIR DO CABE√áALHO'} 
- Setor: ${context.businessSector || 'INFERIR DA ATIVIDADE'}

INSTRU√á√ïES CR√çTICAS PARA AN√ÅLISE:`;

  // Add specialized instructions based on context
  if (context.licenseType?.includes('LP')) {
    basePrompt += `
AN√ÅLISE ESPEC√çFICA PARA LICEN√áA PR√âVIA (LP):
- Foque em viabilidade ambiental e localiza√ß√£o
- Identifique estudos ambientais exigidos (EIA/RIMA, EAS, RCA)
- Extraia condicionantes de concep√ß√£o e alternativas tecnol√≥gicas
- Analise restri√ß√µes de localiza√ß√£o e dist√¢ncias m√≠nimas
- Identifique exig√™ncias para fase de LI
`;
  } else if (context.licenseType?.includes('LI')) {
    basePrompt += `
AN√ÅLISE ESPEC√çFICA PARA LICEN√áA DE INSTALA√á√ÉO (LI):
- Foque em especifica√ß√µes t√©cnicas e cronogramas
- Extraia condicionantes de constru√ß√£o e instala√ß√£o  
- Identifique sistemas de controle ambiental exigidos
- Analise prazos de obras e marcos de execu√ß√£o
- Identifique documentos para LO
`;
  } else if (context.licenseType?.includes('LO')) {
    basePrompt += `
AN√ÅLISE ESPEC√çFICA PARA LICEN√áA DE OPERA√á√ÉO (LO):
- Foque em condicionantes operacionais e monitoramento
- Extraia frequ√™ncias de relat√≥rios e monitoramentos
- Identifique par√¢metros de emiss√µes e efluentes
- Analise obriga√ß√µes de automonitoramento
- Calcule cronograma de renova√ß√£o (geralmente 4-10 anos)
`;
  }

  if (context.issuingBody?.includes('IBAMA')) {
    basePrompt += `
ESPECIFICIDADES DO IBAMA:
- Atividades de significativo impacto ambiental nacional
- Foco em fauna, flora e unidades de conserva√ß√£o
- Condicionantes federais espec√≠ficas
- Prazos e procedimentos federais
`;
  } else if (context.issuingBody?.includes('CETESB')) {
    basePrompt += `
ESPECIFICIDADES DA CETESB (SP):
- Padr√µes de qualidade do ar de S√£o Paulo
- CADRI para res√≠duos industriais  
- Emiss√µes veiculares e combust√≠veis
- Licenciamento por porte e potencial poluidor
`;
  }

  if (context.businessSector?.includes('minera√ß√£o')) {
    basePrompt += `
SETOR MINERA√á√ÉO:
- PAE (Plano de Aproveitamento Econ√¥mico)
- PRAD (Plano de Recupera√ß√£o de √Årea Degradada)
- Plano de fechamento de mina
- Monitoramento de √°guas subterr√¢neas
`;
  } else if (context.businessSector?.includes('petr√≥leo')) {
    basePrompt += `
SETOR PETR√ìLEO & G√ÅS:
- Planos de emerg√™ncia individual (PEI)
- Estudos de dispers√£o de √≥leo
- Monitoramento da biota aqu√°tica
- An√°lise de risco ecol√≥gico
`;
  }

  basePrompt += `
üöÄ EXECU√á√ÉO DA AN√ÅLISE:

1. DADOS FUNDAMENTAIS (OBRIGAT√ìRIOS):
   üìã NOME: T√≠tulo completo da licen√ßa (geralmente no cabe√ßalho)
   üè∑Ô∏è TIPO: LP/LI/LO/LAS/LAU/etc. (procure ap√≥s "Licen√ßa de" ou sozinho)
   üèõÔ∏è √ìRG√ÉO: Nome completo do √≥rg√£o emissor (cabe√ßalho com logotipo)
   üìã PROCESSO: N√∫mero completo do processo (ap√≥s "Processo n¬∫")
   üìÖ EMISS√ÉO: Data de emiss√£o (procure "emitida em", formato DD/MM/AAAA)
   ‚è∞ VENCIMENTO: Data limite (procure "v√°lida at√©", "vencimento")
   ‚úÖ STATUS: Calcule baseado na data atual vs vencimento

2. ESTRAT√âGIAS PARA CONDICIONANTES:
   üîç LOCALIZE por: "fica condicionado", "dever√°", "obriga-se", "√© obrigat√≥rio"
   üìù EXTRAIA: Texto completo sem cortes
   üè∑Ô∏è CATEGORIZE: monitoramento, relat√≥rio, obra, programa, compensa√ß√£o
   ‚ö° PRIORIDADE: high (multas/suspens√£o), medium (advert√™ncia), low (informativo)
   üîÑ FREQU√äNCIA: Procure "mensalmente", "anualmente", "at√© DD/MM"
   üë• RESPONS√ÅVEL: Inferir pela natureza (ambiental, operacional, t√©cnico)

3. CONFIDENCE SCORES INTELIGENTES:
   100: Informa√ß√£o expl√≠cita e clara no documento
   80-99: Informa√ß√£o evidente mas requer interpreta√ß√£o m√≠nima
   60-79: Informa√ß√£o inferida com base em contexto s√≥lido
   40-59: Informa√ß√£o estimada com padr√µes conhecidos
   20-39: Informa√ß√£o parcial ou incerta
   0-19: Informa√ß√£o n√£o encontrada ou altamente duvidosa

4. VALIDA√á√ïES OBRIGAT√ìRIAS:
   ‚úÖ Datas em formato brasileiro (DD/MM/AAAA)
   ‚úÖ √ìrg√£o deve estar na lista conhecida de √≥rg√£os ambientais
   ‚úÖ Tipo de licen√ßa deve ser c√≥digo v√°lido (LP, LI, LO, etc.)
   ‚úÖ Status derivado logicamente das datas
   ‚úÖ Condicionantes devem ter sentido t√©cnico

‚ö†Ô∏è REGRAS CR√çTICAS DE RESPOSTA:
- Responda EXCLUSIVAMENTE em formato JSON v√°lido
- Use confidence scores REALISTAS (0-100)
- Para campos n√£o encontrados: "" (string), [] (array), 0 (number)
- Datas SEMPRE no formato YYYY-MM-DD (converter de DD/MM/AAAA)
- Seja CONSERVADOR nos confidence scores se houver d√∫vida

üìã FORMATO JSON OBRIGAT√ìRIO:
{
  "nome": "Licen√ßa de Opera√ß√£o - [Nome da Atividade]",
  "tipo": "LO", 
  "orgaoEmissor": "CETESB - Companhia Ambiental do Estado de S√£o Paulo",
  "numeroProcesso": "123456.789.012/2023-SP",
  "dataEmissao": "2023-05-15",
  "dataVencimento": "2033-05-14", 
  "status": "Ativa",
  "condicionantes": "Texto completo das condicionantes encontradas no documento...",
  "structured_conditions": [
    {
      "condition_text": "Realizar monitoramento mensal da qualidade do ar",
      "condition_category": "monitoramento_continuo",
      "priority": "high",
      "frequency": "Mensal",
      "due_date": "2024-01-30",
      "responsible_area": "Meio Ambiente",
      "compliance_status": "pending"
    }
  ],
  "alerts": [
    {
      "type": "renewal",
      "title": "Licen√ßa pr√≥xima ao vencimento",
      "message": "Iniciar processo de renova√ß√£o em 18 meses", 
      "severity": "medium",
      "due_date": "2031-11-14",
      "action_required": true
    }
  ],
  "compliance_score": 85,
  "renewal_recommendation": {
    "start_date": "2031-05-15",
    "urgency": "medium", 
    "required_documents": ["EIA/RIMA atualizado", "Relat√≥rios de monitoramento"],
    "estimated_cost": 150000,
    "recommended_actions": ["Contratar consultoria especializada", "Atualizar estudos ambientais"]
  },
  "confidence_scores": {
    "nome": 95,
    "tipo": 90,
    "orgaoEmissor": 88,
    "numeroProcesso": 85,
    "dataEmissao": 92,
    "dataVencimento": 90,
    "status": 95,
    "condicionantes": 75
  }
}

üìÑ CONTE√öDO DO DOCUMENTO PARA AN√ÅLISE:
${documentContent}

üéØ EXECUTE A AN√ÅLISE AGORA COM M√ÅXIMA INTELIG√äNCIA E PRECIS√ÉO!
`;

  return basePrompt;
}

// Utility function to extract JSON from text that might contain code blocks or other noise
function extractJsonFromText(text: string): any {
  // Remove any markdown code block markers
  let cleanText = text.replace(/```json\s*/g, '').replace(/```\s*/g, '');
  
  // Try to find JSON content between braces
  const jsonMatch = cleanText.match(/\{[\s\S]*\}/);
  if (jsonMatch) {
    cleanText = jsonMatch[0];
  }
  
  // Trim whitespace
  cleanText = cleanText.trim();
  
  try {
    return JSON.parse(cleanText);
  } catch (error) {
    // If that fails, try to extract just the JSON object
    const startBrace = cleanText.indexOf('{');
    const endBrace = cleanText.lastIndexOf('}');
    
    if (startBrace !== -1 && endBrace !== -1 && endBrace > startBrace) {
      const jsonPart = cleanText.substring(startBrace, endBrace + 1);
      return JSON.parse(jsonPart);
    }
    
    throw new Error(`Invalid JSON format: ${error.message}`);
  }
}

function detectLicenseContext(content: string): LicenseContext {
  const context: LicenseContext = {};
  
  // Enhanced license type detection with more patterns
  const licensePatterns = [
    { pattern: /licen[√ßc]a pr[√©e]via|LP\b/i, type: 'LP' },
    { pattern: /licen[√ßc]a de instala[√ßc][√£a]o|LI\b/i, type: 'LI' },
    { pattern: /licen[√ßc]a de opera[√ßc][√£a]o|LO\b/i, type: 'LO' },
    { pattern: /licen[√ßc]a ambiental simplificada|LAS\b/i, type: 'LAS' },
    { pattern: /licen[√ßc]a ambiental [√∫u]nica|LAU\b/i, type: 'LAU' },
    { pattern: /licen[√ßc]a ambiental corretiva|LAC\b/i, type: 'LAC' },
    { pattern: /renova[√ßc][√£a]o de licen[√ßc]a|RLO\b/i, type: 'RLO' },
    { pattern: /autoriza[√ßc][√£a]o para atividade|AAF\b/i, type: 'AAF' }
  ];
  
  for (const { pattern, type } of licensePatterns) {
    if (content.match(pattern)) {
      context.licenseType = type;
      break;
    }
  }
  
  // Enhanced issuing body detection
  const issuingBodies = [
    { pattern: /IBAMA|Instituto Brasileiro do Meio Ambiente/i, name: 'IBAMA' },
    { pattern: /CETESB|Companhia Ambiental do Estado de S[√£a]o Paulo/i, name: 'CETESB' },
    { pattern: /FEPAM|Funda[√ßc][√£a]o Estadual de Prote[√ßc][√£a]o Ambiental/i, name: 'FEPAM' },
    { pattern: /INEA|Instituto Estadual do Ambiente/i, name: 'INEA' },
    { pattern: /FATMA|Funda[√ßc][√£a]o do Meio Ambiente/i, name: 'FATMA' },
    { pattern: /FEAM|Funda[√ßc][√£a]o Estadual do Meio Ambiente/i, name: 'FEAM' },
    { pattern: /IAP|Instituto Ambiental do Paran[√°a]/i, name: 'IAP' },
    { pattern: /SEMAC|Secretaria de Estado de Meio Ambiente/i, name: 'SEMAC' },
    { pattern: /SEMA|Secretaria do Meio Ambiente/i, name: 'SEMA' },
    { pattern: /ADEMA|Administra[√ßc][√£a]o Estadual do Meio Ambiente/i, name: 'ADEMA' }
  ];
  
  for (const { pattern, name } of issuingBodies) {
    if (content.match(pattern)) {
      context.issuingBody = name;
      break;
    }
  }
  
  // Detect business sector
  if (content.match(/minera[√ßc][√£a]o|extrat|lavra|mina\b/i)) {
    context.businessSector = 'minera√ß√£o';
  } else if (content.match(/petr[√≥o]leo|g[√°a]s|refinaria|E&P/i)) {
    context.businessSector = 'petr√≥leo';
  } else if (content.match(/sider[√∫u]rgica|metalurgia|a[√ßc]o\b/i)) {
    context.businessSector = 'siderurgia';
  } else if (content.match(/qu[√≠i]mica|farmac[√™e]utica|petroqu[√≠i]mica/i)) {
    context.businessSector = 'qu√≠mica';
  }
  
  return context;
}

// Enhanced PDF text extraction with comprehensive strategies
async function extractPdfText(fileBlob: Blob): Promise<string> {
  try {
    console.log('Starting comprehensive PDF text extraction...');
    const arrayBuffer = await fileBlob.arrayBuffer();
    const uint8Array = new Uint8Array(arrayBuffer);
    
    let text = '';
    let textualContent = 0; // Count meaningful textual content
    let totalChars = 0;
    
    // STRATEGY 1: Look for text objects (BT...ET blocks) with enhanced patterns
    console.log('Attempting text object extraction...');
    let i = 0;
    while (i < uint8Array.length - 10) {
      // Look for text objects (BT...ET blocks)
      if (uint8Array[i] === 0x42 && uint8Array[i+1] === 0x54 && uint8Array[i+2] === 0x20) { // "BT "
        i += 3;
        let textBlock = '';
        
        // Extract text until ET
        while (i < uint8Array.length - 3) {
          if (uint8Array[i] === 0x45 && uint8Array[i+1] === 0x54 && uint8Array[i+2] === 0x20) { // "ET "
            break;
          }
          
          // Look for Tj or TJ commands (text showing operators)
          if (uint8Array[i] === 0x28) { // Start of text string "("
            i++;
            let textContent = '';
            while (i < uint8Array.length && uint8Array[i] !== 0x29) { // Until ")"
              if (uint8Array[i] >= 32 && uint8Array[i] <= 126) {
                textContent += String.fromCharCode(uint8Array[i]);
                totalChars++;
                if (/[a-zA-Z√°√©√≠√≥√∫√†√®√¨√≤√π√¢√™√Æ√¥√ª√£√µ√ß√Å√â√ç√ì√ö√Ä√à√å√í√ô√Ç√ä√é√î√õ√É√ï√á]/.test(String.fromCharCode(uint8Array[i]))) {
                  textualContent++;
                }
              }
              i++;
            }
            if (textContent.trim().length > 2) {
              textBlock += textContent + ' ';
            }
          }
          i++;
        }
        
        if (textBlock.trim().length > 5) {
          text += textBlock.trim() + '\n';
        }
      }
      i++;
    }
    
    // STRATEGY 2: Enhanced fallback - look for readable ASCII sequences
    if (text.length < 200) {
      console.log('Primary extraction insufficient, trying enhanced fallback...');
      let fallbackText = '';
      let consecutiveLetters = 0;
      let currentWord = '';
      
      for (let j = 0; j < uint8Array.length; j++) {
        const char = uint8Array[j];
        if (char >= 32 && char <= 126) { // Printable ASCII
          const charStr = String.fromCharCode(char);
          currentWord += charStr;
          totalChars++;
          
          if (/[a-zA-Z√°√©√≠√≥√∫√†√®√¨√≤√π√¢√™√Æ√¥√ª√£√µ√ß√Å√â√ç√ì√ö√Ä√à√å√í√ô√Ç√ä√é√î√õ√É√ï√á]/.test(charStr)) {
            consecutiveLetters++;
            textualContent++;
          } else if (/[\s\-\.]/.test(charStr) && currentWord.length > 2) {
            // End of a word - add to text if meaningful
            if (consecutiveLetters >= 3) {
              fallbackText += currentWord;
            }
            currentWord = '';
            consecutiveLetters = 0;
          } else {
            consecutiveLetters = 0;
          }
          
          // Reset word if it gets too long without meaning
          if (currentWord.length > 50) {
            currentWord = '';
            consecutiveLetters = 0;
          }
        } else if (char === 10 || char === 13) {
          // Newline - finish current word and add newline
          if (currentWord.length > 2 && consecutiveLetters >= 3) {
            fallbackText += currentWord;
          }
          fallbackText += '\n';
          currentWord = '';
          consecutiveLetters = 0;
        } else {
          // Non-printable character - finish current word
          if (currentWord.length > 2 && consecutiveLetters >= 3) {
            fallbackText += currentWord + ' ';
          }
          currentWord = '';
          consecutiveLetters = 0;
        }
      }
      
      // Add final word if meaningful
      if (currentWord.length > 2 && consecutiveLetters >= 3) {
        fallbackText += currentWord;
      }
      
      if (fallbackText.length > text.length) {
        text = fallbackText;
        console.log('Enhanced fallback extraction used');
      }
    }
    
    // STRATEGY 3: Unicode and extended character support
    if (text.length < 300) {
      console.log('Attempting Unicode-aware extraction...');
      let unicodeText = '';
      
      // Look for UTF-8 encoded text patterns
      for (let k = 0; k < uint8Array.length - 2; k++) {
        // Check for multi-byte UTF-8 sequences
        if ((uint8Array[k] & 0xE0) === 0xC0) { // 2-byte UTF-8
          const char1 = uint8Array[k];
          const char2 = uint8Array[k + 1];
          if ((char2 & 0xC0) === 0x80) {
            const codePoint = ((char1 & 0x1F) << 6) | (char2 & 0x3F);
            if (codePoint >= 0x80) {
              unicodeText += String.fromCharCode(codePoint);
              k++; // Skip next byte
            }
          }
        } else if ((uint8Array[k] & 0xF0) === 0xE0) { // 3-byte UTF-8
          const char1 = uint8Array[k];
          const char2 = uint8Array[k + 1];
          const char3 = uint8Array[k + 2];
          if ((char2 & 0xC0) === 0x80 && (char3 & 0xC0) === 0x80) {
            const codePoint = ((char1 & 0x0F) << 12) | ((char2 & 0x3F) << 6) | (char3 & 0x3F);
            if (codePoint >= 0x800) {
              unicodeText += String.fromCharCode(codePoint);
              k += 2; // Skip next two bytes
            }
          }
        }
      }
      
      if (unicodeText.length > text.length) {
        text = unicodeText;
        console.log('Unicode extraction provided better results');
      }
    }
    
    // Calculate text quality ratio
    const textQuality = totalChars > 0 ? (textualContent / totalChars) : 0;
    console.log(`PDF extraction stats: total chars: ${totalChars}, textual: ${textualContent}, quality ratio: ${textQuality.toFixed(2)}`);
    
    // Enhanced text cleaning while preserving structure
    const cleanedText = text
      .replace(/[^\w\s\-\/\(\)\.\,\:\;\n\r\u00C0-\u017F]/g, ' ') // Allow accented characters
      .replace(/\s+/g, ' ') // Normalize spaces
      .replace(/(\n\s*){3,}/g, '\n\n') // Limit consecutive newlines
      .trim();
    
    // Log quality metrics
    const finalLength = cleanedText.length;
    const wordCount = cleanedText.split(/\s+/).filter(word => word.length > 2).length;
    console.log(`Final PDF content: ${finalLength} chars, ${wordCount} words, quality: ${textQuality > 0.3 ? 'Good' : textQuality > 0.1 ? 'Fair' : 'Poor'}`);
    
    return cleanedText.substring(0, 25000); // Increased limit for comprehensive extraction
  } catch (error) {
    console.error('PDF text extraction error:', error);
    return '';
  }
}

// Conservative heuristic extraction - only extract if very confident
function heuristicExtractFromFileName(fileName: string): Partial<ExtractedLicenseFormData> {
  console.log(`Attempting conservative heuristic extraction from filename: ${fileName}`);
  
  // Skip temporary files
  if (fileName.includes('temp-') || fileName.length < 10) {
    console.log('Skipping heuristic extraction due to temporary filename pattern');
    return {};
  }
  
  const data: Partial<ExtractedLicenseFormData> = {};
  
  // Only extract very obvious patterns
  const licenseTypeMatch = fileName.match(/\b(LP|LI|LO|LAS|LAU|LAC)\b/i);
  if (licenseTypeMatch) {
    data.tipo = licenseTypeMatch[1].toUpperCase();
  }
  
  // Only extract if there's a clear year pattern (2020-2030 range)
  const yearMatch = fileName.match(/\b(202[0-9]|203[0-9])\b/);
  if (yearMatch && licenseTypeMatch) {
    // Only set status if we have both type and year
    data.status = 'Ativa';
  }
  
  // Only extract organization if very clear pattern
  const orgMatch = fileName.match(/\b(IBAMA|CETESB|INEA|FATMA|FEAM|IAP|SEMAC)\b/i);
  if (orgMatch) {
    data.orgaoEmissor = orgMatch[1].toUpperCase();
  }
  
  console.log('Conservative heuristic extraction result:', data);
  return data;
}

function parseDate(dateStr: string): string {
  if (!dateStr) return '';
  
  try {
    // Handle DD/MM/YYYY format
    const ddmmyyyy = dateStr.match(/(\d{1,2})\/(\d{1,2})\/(\d{4})/);
    if (ddmmyyyy) {
      const [, day, month, year] = ddmmyyyy;
      return `${year}-${month.padStart(2, '0')}-${day.padStart(2, '0')}`;
    }
    
    // Handle YYYY-MM-DD format (already correct)
    const yyyymmdd = dateStr.match(/(\d{4})-(\d{1,2})-(\d{1,2})/);
    if (yyyymmdd) {
      return dateStr;
    }
    
    // Handle written dates like "15 de janeiro de 2023"
    const writtenDate = dateStr.match(/(\d{1,2})\s+de\s+(\w+)\s+de\s+(\d{4})/i);
    if (writtenDate) {
      const [, day, monthName, year] = writtenDate;
      const monthMap: { [key: string]: string } = {
        'janeiro': '01', 'fevereiro': '02', 'mar√ßo': '03', 'abril': '04',
        'maio': '05', 'junho': '06', 'julho': '07', 'agosto': '08',
        'setembro': '09', 'outubro': '10', 'novembro': '11', 'dezembro': '12'
      };
      const month = monthMap[monthName.toLowerCase()];
      if (month) {
        return `${year}-${month}-${day.padStart(2, '0')}`;
      }
    }
    
    return '';
  } catch (error) {
    console.error('Error parsing date:', error);
    return '';
  }
}

async function parseSpreadsheet(fileBlob: Blob, fileType: string): Promise<string> {
  console.log(`Parsing spreadsheet of type: ${fileType}`);
  
  if (fileType.includes('csv')) {
    const text = await fileBlob.text();
    return text.substring(0, 10000); // First 10k chars
  }
  
  // For Excel files, convert to text representation
  const arrayBuffer = await fileBlob.arrayBuffer();
  const uint8Array = new Uint8Array(arrayBuffer);
  
  let text = '';
  // Simple extraction of readable text from Excel files
  for (let i = 0; i < uint8Array.length; i++) {
    const char = uint8Array[i];
    if (char >= 32 && char <= 126) {
      text += String.fromCharCode(char);
    } else if (char === 10 || char === 13) {
      text += '\n';
    }
  }
  
  return text.substring(0, 10000);
}

function getFileType(fileName: string): string {
  const extension = fileName.split('.').pop()?.toLowerCase() || '';
  
  if (extension === 'pdf') return 'pdf';
  if (['xlsx', 'xls', 'csv'].includes(extension)) return 'spreadsheet';
  if (['jpg', 'jpeg', 'png', 'webp'].includes(extension)) return 'image';
  
  return extension;
}

serve(async (req) => {
  // Handle CORS preflight requests
  if (req.method === 'OPTIONS') {
    return new Response(null, { headers: corsHeaders });
  }

  try {
    console.log('Starting comprehensive document analysis...');

    const openaiApiKey = Deno.env.get('OPENAI_API_KEY');
    if (!openaiApiKey) {
      console.error('OpenAI API key not found');
      return new Response(JSON.stringify({ 
        success: false, 
        error: 'OpenAI API key not configured' 
      }), {
        status: 500,
        headers: { ...corsHeaders, 'Content-Type': 'application/json' },
      });
    }

    // Initialize Supabase client
    const supabaseUrl = Deno.env.get('SUPABASE_URL')!;
    const supabaseServiceKey = Deno.env.get('SUPABASE_SERVICE_ROLE_KEY')!;
    const supabase = createClient(supabaseUrl, supabaseServiceKey);

    // Verify authentication
    const authHeader = req.headers.get('authorization');
    if (!authHeader) {
      console.error('Authorization header missing');
      return new Response(JSON.stringify({ 
        success: false, 
        error: 'Authorization required' 
      }), {
        status: 401,
        headers: { ...corsHeaders, 'Content-Type': 'application/json' },
      });
    }

    const token = authHeader.replace('Bearer ', '');
    const { data: { user }, error: authError } = await supabase.auth.getUser(token);
    
    if (authError || !user) {
      console.error('Authentication failed:', authError);
      return new Response(JSON.stringify({ 
        success: false, 
        error: 'Authentication failed' 
      }), {
        status: 401,
        headers: { ...corsHeaders, 'Content-Type': 'application/json' },
      });
    }

    console.log('Starting document analysis for user:', user.id);

    const { documentPath }: DocumentAnalysisRequest = await req.json();
    console.log('Analyzing document:', documentPath);

    if (!documentPath) {
      return new Response(JSON.stringify({ 
        success: false, 
        error: 'Document path is required' 
      }), {
        status: 400,
        headers: { ...corsHeaders, 'Content-Type': 'application/json' },
      });
    }

    // Download the document from Supabase Storage
    const { data: fileData, error: downloadError } = await supabase.storage
      .from('documents')
      .download(documentPath);

    if (downloadError) {
      console.error('Error downloading file:', downloadError);
      return new Response(JSON.stringify({ 
        success: false, 
        error: 'Failed to download document' 
      }), {
        status: 500,
        headers: { ...corsHeaders, 'Content-Type': 'application/json' },
      });
    }

    const fileName = documentPath.split('/').pop() || 'document';
    const fileType = getFileType(fileName);
    console.log('File type detected:', fileType, 'for file:', fileName);

    let documentContent = '';
    let analysisType = 'text';
    let imageUrl = '';
    let analysisStartTime = Date.now();

    // FASE 1: EXTRA√á√ÉO PROGRESSIVA DE CONTE√öDO
    console.log('=== FASE 1: EXTRA√á√ÉO DE CONTE√öDO ===');
    
    if (fileType === 'pdf') {
      console.log('Extracting text from PDF (comprehensive analysis)...');
      const extractedText = await extractPdfText(fileData);
      
      console.log(`PDF extraction results: ${extractedText.length} characters, ${extractedText.split(' ').filter(w => w.length > 2).length} words`);
      
      // Threshold mais baixo para tentar an√°lise de texto primeiro
      if (extractedText.length < 150 || extractedText.split(' ').filter(word => word.length > 2).length < 15) {
        console.log('PDF text extraction insufficient, preparing vision analysis...');
        
        // Upload temporary file for vision analysis
        const tempVisionPath = `temp-vision-${Date.now()}-${Math.random().toString(36).substr(2, 9)}.pdf`;
        const { data: uploadData, error: uploadError } = await supabase.storage
          .from('documents')
          .upload(tempVisionPath, fileData, {
            contentType: 'application/pdf',
            cacheControl: '300'
          });
        
        if (!uploadError && uploadData) {
          const { data: urlData } = await supabase.storage
            .from('documents')
            .createSignedUrl(uploadData.path, 1800); // 30 min
          
          if (urlData?.signedUrl) {
            imageUrl = urlData.signedUrl;
            analysisType = 'vision_pdf';
            documentContent = `PDF document requiring vision analysis: ${fileName}\nExtracted text preview: ${extractedText.substring(0, 300)}`;
          }
        }
        
        if (!imageUrl) {
          documentContent = extractedText; // Fallback to whatever text we got
          analysisType = 'text_fallback';
        }
      } else {
        documentContent = extractedText;
        analysisType = 'text';
      }
    } else if (['jpg', 'jpeg', 'png', 'webp'].includes(fileType)) {
      console.log('Processing image document for vision analysis...');
      
      const tempImagePath = `temp-vision-${Date.now()}-${Math.random().toString(36).substr(2, 9)}.${fileType}`;
      const { data: uploadData, error: uploadError } = await supabase.storage
        .from('documents')
        .upload(tempImagePath, fileData, {
          contentType: fileData.type,
          cacheControl: '300'
        });
      
      if (!uploadError && uploadData) {
        const { data: urlData } = await supabase.storage
          .from('documents')
          .createSignedUrl(uploadData.path, 1800);
        
        if (urlData?.signedUrl) {
          imageUrl = urlData.signedUrl;
          analysisType = 'vision_image';
          documentContent = `Image document: ${fileName}`;
        }
      }
    } else if (['csv', 'xlsx', 'xls'].includes(fileType)) {
      console.log('Parsing spreadsheet...');
      documentContent = await parseSpreadsheet(fileData, fileType);
      analysisType = 'spreadsheet';
    } else {
      return new Response(JSON.stringify({ 
        success: false, 
        error: 'Unsupported file type. Please upload PDF, image, or spreadsheet files.' 
      }), {
        status: 400,
        headers: { ...corsHeaders, 'Content-Type': 'application/json' },
      });
    }

    // FASE 2: AN√ÅLISE INTELIGENTE COM IA
    console.log(`=== FASE 2: AN√ÅLISE IA (${analysisType.toUpperCase()}) ===`);

    // Minimum processing time to ensure thorough analysis
    const minProcessingTime = 15000; // 15 seconds minimum
    
    console.log('Calling OpenAI API for comprehensive analysis...');

    // Configura√ß√£o aprimorada do modelo
    const openaiPayload: any = {
      model: 'gpt-4.1-2025-04-14', // GPT-4.1 para an√°lise profunda
      max_completion_tokens: 6000, // Aumentado para an√°lise completa
      response_format: { type: "json_object" }
    };

    // Configurar mensagens baseado no tipo de an√°lise
    if (analysisType.startsWith('vision') && imageUrl) {
      console.log('Using vision analysis for document understanding...');
      openaiPayload.messages = [
        {
          role: 'system',
          content: `Voc√™ √© um especialista S√äNIOR em licenciamento ambiental brasileiro com 20+ anos de experi√™ncia. 
          Analise minuciosamente a imagem do documento fornecida e extraia TODAS as informa√ß√µes de licenciamento poss√≠veis.
          
          ESTRAT√âGIAS VISUAIS ESPEC√çFICAS:
          - Examine cabe√ßalhos, logotipos e timbres para identificar √≥rg√£os
          - Localize n√∫meros de processo em caixas ou campos destacados
          - Procure datas em formatos brasileiros (DD/MM/AAAA)
          - Identifique condicionantes em listas numeradas ou com bullets
          - Analise assinaturas e carimbos para valida√ß√£o
          
          Use o m√°ximo de detalhamento poss√≠vel e seja conservador nos confidence scores apenas se realmente n√£o conseguir ler algo.`
        },
        {
          role: 'user',
          content: [
            {
              type: 'text',
              content: getSpecializedPrompt(documentContent)
            },
            {
              type: 'image_url',
              image_url: {
                url: imageUrl,
                detail: 'high'
              }
            }
          ]
        }
      ];
    } else {
      console.log('Using text analysis for document understanding...');
      openaiPayload.messages = [
        {
          role: 'system',
          content: `Voc√™ √© um especialista S√äNIOR em licenciamento ambiental brasileiro com 20+ anos de experi√™ncia.
          Analise o texto fornecido com m√°xima profundidade e extraia TODAS as informa√ß√µes de licenciamento dispon√≠veis.
          
          ESTRAT√âGIAS DE TEXTO ESPEC√çFICAS:
          - Use reconhecimento de padr√µes brasileiros de documentos oficiais
          - Identifique estruturas t√≠picas de licen√ßas (cabe√ßalho, corpo, condicionantes, assinaturas)
          - Procure por palavras-chave em portugu√™s brasileiro
          - Valide informa√ß√µes cruzando m√∫ltiplas se√ß√µes do documento
          - Seja detalhista na extra√ß√£o de condicionantes e prazos
          
          Dedique tempo suficiente para uma an√°lise completa e precisa.`
        },
        {
          role: 'user',
          content: getSpecializedPrompt(documentContent)
        }
      ];
    }

    const openaiResponse = await fetch('https://api.openai.com/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${openaiApiKey}`,
        'Content-Type': 'application/json',
      },
      body: JSON.stringify(openaiPayload),
    });

    if (!openaiResponse.ok) {
      const errorText = await openaiResponse.text();
      console.error('OpenAI API error:', errorText);
      return new Response(JSON.stringify({ 
        success: false, 
        error: 'AI analysis service temporarily unavailable. Please try again.' 
      }), {
        status: 500,
        headers: { ...corsHeaders, 'Content-Type': 'application/json' },
      });
    }

    const aiResponse = await openaiResponse.json();
    console.log('OpenAI analysis completed');

    // FASE 3: PROCESSAMENTO E VALIDA√á√ÉO DOS RESULTADOS
    console.log('=== FASE 3: PROCESSAMENTO DOS RESULTADOS ===');

    let extractedData: ExtractedLicenseFormData;
    
    try {
      const content = aiResponse.choices[0].message.content;
      console.log('AI response length:', content.length);
      extractedData = extractJsonFromText(content);
    } catch (parseError) {
      console.error('Failed to parse AI response:', parseError);
      
      // Fallback to heuristic analysis
      console.log('Attempting heuristic fallback analysis...');
      const heuristicData = heuristicExtractFromFileName(fileName);
      
      if (Object.values(heuristicData).some(val => val && val !== '')) {
        extractedData = {
          ...heuristicData,
          condicionantes: '',
          structured_conditions: [],
          alerts: [],
          compliance_score: 0,
          renewal_recommendation: {
            start_date: '',
            urgency: 'medium',
            required_documents: [],
            estimated_cost: 0,
            recommended_actions: []
          },
          confidence_scores: {
            nome: 20,
            tipo: 20,
            orgaoEmissor: 15,
            numeroProcesso: 15,
            dataEmissao: 15,
            dataVencimento: 15,
            status: 20,
            condicionantes: 10
          }
        } as ExtractedLicenseFormData;
      } else {
        return new Response(JSON.stringify({ 
          success: false, 
          error: 'Failed to parse document content. The document may be corrupted or in an unsupported format.' 
        }), {
          status: 500,
          headers: { ...corsHeaders, 'Content-Type': 'application/json' },
        });
      }
    }

    // Calcular confian√ßa geral com pesos ajustados
    const confidenceValues = Object.values(extractedData.confidence_scores || {});
    const weightedConfidence = confidenceValues.length > 0 
      ? Math.round(confidenceValues.reduce((a, b) => a + b, 0) / confidenceValues.length)
      : 0;

    // Verificar se encontrou dados cr√≠ticos
    const criticalDataScore = [
      extractedData.nome ? 25 : 0,
      extractedData.tipo ? 20 : 0,
      extractedData.orgaoEmissor ? 15 : 0,
      extractedData.numeroProcesso ? 20 : 0,
      extractedData.dataEmissao ? 10 : 0,
      extractedData.dataVencimento ? 10 : 0
    ].reduce((a, b) => a + b, 0);

    const finalConfidence = Math.max(weightedConfidence, Math.floor(criticalDataScore * 0.8));

    // Tempo m√≠nimo de processamento para passar credibilidade
    const processingTime = Date.now() - analysisStartTime;
    if (processingTime < minProcessingTime) {
      const remainingTime = minProcessingTime - processingTime;
      console.log(`Ensuring minimum processing time: waiting ${remainingTime}ms...`);
      await new Promise(resolve => setTimeout(resolve, remainingTime));
    }

    console.log(`Analysis completed: confidence=${finalConfidence}%, type=${analysisType}, processing_time=${Date.now() - analysisStartTime}ms`);

    // VALIDA√á√ÉO FINAL - threshold reduzido para 20%
    if (finalConfidence < 20 && criticalDataScore < 30) {
      console.log('Analysis confidence below threshold, providing guidance to user...');
      
      return new Response(JSON.stringify({ 
        success: false, 
        error: 'Document analysis incomplete. This may be due to: poor document quality, scanned/image-based PDF, or non-standard license format. Please try: 1) Upload a higher quality document, 2) Ensure the document contains visible license information, 3) Enter information manually using the form below.',
        analysis_attempted: true,
        analysis_type: analysisType,
        partial_data: extractedData,
        confidence: finalConfidence
      }), {
        status: 400,
        headers: { ...corsHeaders, 'Content-Type': 'application/json' },
      });
    }

    // LIMPEZA DE ARQUIVOS TEMPOR√ÅRIOS
    if (imageUrl && (analysisType.startsWith('vision'))) {
      try {
        const urlParts = imageUrl.split('/');
        const tempFileName = urlParts[urlParts.length - 1].split('?')[0];
        if (tempFileName.startsWith('temp-vision-')) {
          await supabase.storage.from('documents').remove([tempFileName]);
          console.log('Temporary vision file cleaned up');
        }
      } catch (cleanupError) {
        console.log('Cleanup warning (non-critical):', cleanupError);
      }
    }

    // Limpeza do arquivo original se tempor√°rio
    try {
      if (documentPath.includes('temp/')) {
        await supabase.storage.from('documents').remove([documentPath]);
        console.log('Original temporary file cleaned up');
      }
    } catch (cleanupError) {
      console.log('Original file cleanup warning (non-critical):', cleanupError);
    }

    return new Response(JSON.stringify({
      success: true,
      extracted_data: extractedData,
      overall_confidence: finalConfidence,
      analysis_type: analysisType,
      file_type: fileType,
      analysis_timestamp: new Date().toISOString(),
      processing_time_ms: Date.now() - analysisStartTime
    }), {
      headers: { ...corsHeaders, 'Content-Type': 'application/json' },
    });

  } catch (error) {
    console.error('Error in license-document-analyzer:', error);
    return new Response(JSON.stringify({ 
      success: false, 
      error: 'Internal server error during document analysis. Please try again or contact support if the issue persists.' 
    }), {
      status: 500,
      headers: { ...corsHeaders, 'Content-Type': 'application/json' },
    });
  }
});